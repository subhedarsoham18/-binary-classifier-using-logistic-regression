# -binary-classifier-using-logistic-regression
The sigmoid function is the core of logistic regression, used to convert raw input (a linear combination of features) into a probability between 0 and 1.

ğŸ“ Sigmoid Function Formula:
ğœ(ğ‘§)=1/1+ğ‘’âˆ’ğ‘§
Ïƒ(z)= 1+eâˆ’z 1
Where:
ğ‘§=ğ‘¤0+ğ‘¤1ğ‘¥1+ğ‘¤2ğ‘¥2+â‹¯+ğ‘¤ğ‘›ğ‘¥ğ‘›
z=w0+w1x1+w2x2+â‹¯+wnxn
e is Eulerâ€™s number (~2.718)

ğŸ§  What It Does:
Takes any real number 
ğ‘§âˆˆ(âˆ’âˆ,âˆ)
Compresses it into a value 
âˆˆ(0,1)

This value represents the probability of belonging to class 1.
ğŸ“ˆ Sigmoid Curve
The curve is S-shaped, and:

For large negative 
z,ğœ(ğ‘§)â†’0

For large positive 
z, ğœ(ğ‘§)â†’1
At ğ‘§=0
z=0, 
ğœ(0)=0.5
This is why:
If output â‰¥ 0.5 â†’ class 1
If output < 0.5 â†’ class 0
Example:
Suppose:
ğ‘§=2
Then:
ğœ(2)=1/1+ğ‘’âˆ’2â‰ˆ1/1+0.1353â‰ˆ0.88
Ïƒ(2)=1+eâˆ’2
1â‰ˆ 1+0.1353
1â‰ˆ0.88
That means there's an 88% probability of the instance belonging to class 1.

In Logistic Regression:
z = np.dot(weights, inputs) + bias
prob = sigmoid(z)
